{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ushbu amaliy mashg'ulotda *Jupyter Notebook* dasturi orqali Piton dasturlash tilida Qaror daraxti muammosini o'rganamiz.\n",
    "\n",
    "Quyidagi Piton bibliotekalarini yuklab olamiz:\n",
    "- *sklearn* - Pitonda mashinaviy o'qitish algoritmlari bilan ishlash uchun *Scikit-learn* bibliotekasi. Biz ushbu bibliotekadan modelning aniqliligini o'lchashda foydalanamiz.\n",
    "- *load_iris* - *sklearn* bibliotekasining iris ma'lumotlar to'plami paketini yuklab olamiz\n",
    "- - *train_test_split* - *sklearn* bibliotekasining ma'lumotlar to'plamini mashq / test to'plamlarga ajratuvchi paketi\n",
    "- pprint - Pitonda ma'lumotlar strukturasini o'qish uchun qulay chop etadigan biblioteka\n",
    "- math - Pitonda matematik amallar bilan ishlash uchun\n",
    "- *numpy* - Pitonda massivlar bilan ishlash uchun\n",
    "\n",
    "\n",
    "Ushbu mashg'ulotdagi kod https://medium.com/@penggongting/implementing-decision-tree-from-scratch-in-python-c732e7c69aea ssilkadagi yechimga asoslangan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yuqorida ta'kidlaganimizdek, qaror daraxti muammosini o'rganish uchun *iris* ma'lumotlar to'plamidan foydalanamiz. Ushbu to'plam bilan qulayroq ishlash uchun, *sklearn* bibliotekasining *datasets* paketida *load_iris* nomli funksiyas bor va bu funksiya aynan mashinaviy o'qitish algoritmlari uchun moslangan formatdagi *iris* to'plamini taqdim etadi (ya'ni to'plam *numpy* massiv formatida, mashq va nishonlar alohida massivlarga ajratilgan va h.k.). Ushbu to'plam bilan kengroq tanishish uchun quyidagi ssilkaga o'ting: https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avvaliga to'plam entropiyasini hisoblaydigan quyidagi formulani Pitonda ifodalab olamiz:\n",
    "\n",
    "$ Entropy = \\sum_{i}^{n}{- p_i log_2{p_i}} $\n",
    "\n",
    "Yuqoridagi formulada, $n$ - to'plamdagi barcha elementlar soni, $p_i$ - ma'lum bir $i$-klassning ehtimolligi bo'lib, quyidagi formula orqali ifodalasak bo'ladi:\n",
    "$p_i = \\frac{c_i}{n}$, bunda $c_i$ - ma'lum $i$ - klassdagi elementlar soni.\n",
    "\n",
    "Biz yaratayotgan qaror daraxti qoida asosida to'plamni ikkiga bo'lishini hisobga olgan holda, entropiya funksiyasini to'plamda 2 ta klass mavjud deb faraz qilamiz (bunda, $c1$ - birinchi klassdagi elementlar soni, $c2$ - ikkinchi klassdagi elementlar soni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_cal(c1, c2):\n",
    "    \"\"\"\n",
    "    Returns entropy of a group of data\n",
    "    c1: count of one class\n",
    "    c2: count of another class\n",
    "    \"\"\"\n",
    "    if c1== 0 or c2 == 0:  # when there is only one class in the group, entropy is 0\n",
    "        return 0\n",
    "    n = c1 + c2\n",
    "    return -(c1*1.0/n)*math.log(c1*1.0/n, 2) -(c2*1.0/n)*math.log(c2*1.0/n, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To'plam entropiya funksiyasini aniqlab oldik, ammo ushbu funksiya aniq klasslar sonini talab etadi. Amalda esa, ma'lumotlar to'plamidan biz o'zimiz klasslar sonini aniqlab olishimiz, kerak bo'ladi. Ushbu funksiyani yaratamiz, va klasslar bo'yicha har bir bo'linmaning entropiyasini yuqorida yaratilgan $entropy\\_cal$ funksiyasi yordamida topamiz. Va nihoyat, bo'linmaning umumiy entropiyasini aniqlaymiz. Bo'linmaning umumiy entropiyasini quyidagicha ifodalagan edi:\n",
    "$E_U = E_p - (\\frac{n_{b1}}{n_U} \\cdot E_{b1} + \\frac{n_{b2}}{n_U} \\cdot E_{b2} + ... +  \\frac{n_{bn}}{n_U} \\cdot E_{bn})$\n",
    "\n",
    "Yuqoridagi formula, berilgan to'plamning entropiyasi ($ E_p $) hamda ushbu to'plam bo'linmalarining entropiyalarini ($ E_{b1}, E_{b2}, ..., E_{bn} $) hisobga olgan holda, umumiy entropiyani aniqlaydi. Lekin amaliy mashg'ulotda ushbu formulani quyidagicha aniqlaylik:\n",
    "\n",
    "$E_U = - \\frac{n_{b1}}{n_U} \\cdot E_{b1} - \\frac{n_{b2}}{n_U} \\cdot E_{b2} - ... -  \\frac{n_{bn}}{n_U} \\cdot E_{bn})$\n",
    "\n",
    "Ya'ni, bo'linuvchi to'plamning entropiyasi ($E_p$) tushirilib qoldirildi, chunki ushbu entropiyasi ($E_p$) odatda yoki unchalik ahamiyat kasb qilmaydi (agarda, ushbu bo'linuvchi to'plam qaror daraxtining ildiz elementi bo'lsa, yoki yaqin joylashgan bo'lsa), yoki undan oldingi bo'linmalarda ushbu entropiya hisobga olingan bo'ladi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the entropy of one big circle showing above\n",
    "def entropy_of_one_division(division): \n",
    "    \"\"\"\n",
    "    Returns entropy of a divided group of data\n",
    "    Data may have multiple classes\n",
    "    \"\"\"\n",
    "    s = 0\n",
    "    n = len(division)\n",
    "    classes = set(division)\n",
    "    for c in classes:   # for each class, get entropy\n",
    "        n_c = sum(division==c)\n",
    "        e = n_c*1.0/n * entropy_cal(sum(division==c), sum(division!=c)) # weighted avg\n",
    "        s += e\n",
    "    return s, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropiyani aniqlovchi funksiyalarni yaratib olgandan keyin, ushbu funksiyalarni qanday qilib mashq to'plamlariga tatbiq qilish mumkin degan savolga javob izlaymiz. Ushbu savolga javob izlashda, ma'lum bir qadamda qaror daraxti qoida asosida to'plamni ikkiga bo'lishini eslab o'taylik, ya'ni ushbu qoidani qanoatlantiradigan to'plam (aytaylik, $A$ to'plam) va qanoatlantirmaydigan to'plam (aytaylik, $B$ to'plam). Bizning maqsad esa, ushbu $A$ va $B$ to'plamlardagi klasslar qay darajada taqsimlanganini aniqlashdir. Albatta, bu aniqlash biz yuqorida yaratgan entropiya funksiyalari orqali aniqlanadi. Ya'ni, biz ushbu funksiyalarga bo'linma $A$ va $B$ to'plamlari uchun nishonlarni uzatishimiz kerak. Undan oldin esa, biz o'zida faqat nishon klass qiymatlarini saqlovchi $A$ va $B$ bo'linma to'plamlarining nishonlarini alohida ajratib olishimiz kerak. Bunda, biz ma'lum bir qoidaning to'plamga tatbiqini, ya'ni o'zida $True$ (qanoatlantiradigan) hamda $False$ (qanoatlantirmaydigan) qiymatlarni saqlovchi $y\\_predict$ nomli massiv kerak bo'ladi. Bundan tashqari, albatta, biz ustida ishlayotgan to'plamlarning ($A$, $B$) nishonlarini o'zida saqlovchi $y\\_real$ nomli massiv ham talab etiladi. $Numpy$ bibliotekasining funksionalidan foydalangan holda, $y\\_real$ nishonlar massivini $y\\_predict$ massivi orqali ikki to'plamga bo'lamiz. Bunda quyidagi ifodadan foydalangan holda $A$ (ya'ni ma'lum bir qoidani qanoatlantiradigan) to'plam  uchun nishon qiymatlarini olsak:\n",
    "\n",
    "$y\\_real[y\\_predict]$\n",
    "\n",
    "Quyidagi ifodadan foydalangan holda esa, $B$ (ya'ni ma'lum bir qoidani qanoatlantirmaydigan) to'plam  uchun nishon qiymatlarini olamiz:\n",
    "\n",
    "$y\\_real[\\sim y\\_predict]$\n",
    "\n",
    "\n",
    "Yuqorida keltirilgan fikrlarni amalga oshiruvchi $get\\_entropy$ funksiyasini yarataylik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The whole entropy of two big circles combined\n",
    "def get_entropy(y_predict, y_real):\n",
    "    \"\"\"\n",
    "    Returns entropy of a split\n",
    "    y_predict is the split decision, True/Fasle, and y_true can be multi class\n",
    "    \"\"\"\n",
    "    if len(y_predict) != len(y_real):\n",
    "        print('They have to be the same length')\n",
    "        return None\n",
    "    n = len(y_real)\n",
    "    s_true, n_true = entropy_of_one_division(y_real[y_predict]) # left hand side entropy\n",
    "    s_false, n_false = entropy_of_one_division(y_real[~y_predict]) # right hand side entropy\n",
    "    s = n_true*1.0/n * s_true + n_false*1.0/n * s_false # overall entropy, again weighted average\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropiyaga oid kerakli barcha funksiyalarni yaratib oldik. Endi, Qaror daraxtini o'zida ifodalovchi $DecisionTreeClassifier$ Klassni yaratishga kirishamiz. Albatta ushbu klass elementlarini birma-bir yaratib olamiz, hamda so'ngida ushbu elementlardan iborat bo'lgan Qaror daraxti klassini tuzamiz.\n",
    "\n",
    "Avvalambor, Qaror daraxtining maksimal chuqurligini belgilab beruvchi yordamchi o'zgaruvchilarni aniqlab olaylik. Eslatib o'tamiz, ushbu maksimal chuqurlikni belgilab olishdan maqsad - Qaror daraxtining $overfitting$ muammosini hamda cheksiz chuqurlashib ketishini oldini olishdir. Demak, biz $depth$ - qaror daraxtining ma'lum qadamdagi chuqurligini o'zida saqlab turuvchi, va $max\\_depth$ - Qaror daraxtining maksimal chuqurligi (ya'ni qaror daraxti ushbu darajadan chuqur bo'la olmaydi) qiymatlarini o'zida saqlovchi o'zgaruvchilarni yaratib olamiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$DecisionTreeClassifier$ klassining keyingi funksiyasi - $find\\_best\\_split (self, col, y)$ deb atalib, ushbu funksiya ma'lum bir ustun uchun eng minimal entropiyali to'plamlarni hosil qiluvchi qoidani topadi. Buning uchun esa, qatorlar osha yangi sikl yaratilib, shu siklning har bir qadamida ustunning mos qatoridagi qiymat bo'yicha to'plamni ikkiga bo'linadi va minimal entropiyaga solishtirib boriladi (ya'ni ushbu qator qiymati orqali bo'lingan to'plamlar entropiyasi minimal entropiyadan kichik bo'lsa, ushbu qator qiymati minimal entropiya hosil qiluvchi sifatida qabul qilinadi va h.k.). Albatta, sikl so'ngida biz eng optimal qiymatni olamiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(self, col, y):\n",
    "    \"\"\"\n",
    "    col: the column we split on\n",
    "    y: target var\n",
    "    \"\"\"\n",
    "    min_entropy = 10    \n",
    "    n = len(y)\n",
    "    for value in set(col):  # iterating through each value in the column\n",
    "        y_predict = col < value  # separate y into 2 groups\n",
    "        my_entropy = get_entropy(y_predict, y)  # get entropy of this split\n",
    "        if my_entropy <= min_entropy:  # check if it's the best one so far\n",
    "            min_entropy = my_entropy\n",
    "            cutoff = value\n",
    "    return min_entropy, cutoff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ma'lum bir ustundagi minimal entropiyani beruvchi qatorni sikl orqali topishni aniqladik, demak xuddi shu funksiyani ustunlar bo'ylab tatbiq qilib, eng effektiv ustunni (albatta, shu ustunning minimal entropiya beradigan qatorini ham) aniqlashimiz mumkin. Ushbu amalni quyidagi funksiyada aniqlaylik:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_of_all(self, x, y):\n",
    "    \"\"\"\n",
    "    Find the best split from all features\n",
    "    returns: the column to split on, the cutoff value, and the actual entropy\n",
    "    \"\"\"\n",
    "    col = None\n",
    "    min_entropy = 1\n",
    "    cutoff = None\n",
    "    for i, c in enumerate(x.T):  # iterating through each feature\n",
    "        entropy, cur_cutoff = self.find_best_split(c, y)  # find the best split of that feature\n",
    "        if entropy == 0:    # find the first perfect cutoff. Stop Iterating\n",
    "            return i, cur_cutoff, entropy\n",
    "        elif entropy <= min_entropy:  # check if it's best so far\n",
    "            min_entropy = entropy\n",
    "            col = i\n",
    "            cutoff = cur_cutoff\n",
    "    return col, cutoff, min_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eng yaxshi to'plamlarni aniqlaydigan barcha funksiyalarni yaratib oldik. Endi bevosita mashq jarayonini amalga oshiruvchi $fit(...)$ funksiyasini yaratishga o'tsak bo'ladi. Ushbu funksiyaning asosiy maqsadi, yuqoridagi eng yaxshi to'plamlarni aniqlaydigan funksiyalar yordamida berilgan mashq to'plami quyi to'plamlarga bo'lish orqali qoidalar Qaror daraxti shoxlariga 'ilib' chiqishdir. Ya'ni, ildiz element sifatida qaysi qoida, keyingi qadamlardagi qoidalar qanday bo'ladi va h.k.\n",
    "\n",
    "Bundan tashqari, mashq jarayonida to'plamning qaror daraxti yordamida ishlanganini vizual tarzda ko'rish uchun topilgan qoida va so'ngi yaproq elementlarni pitonning $dictionary$ ma'lumotlar strukturasiga qayd qilib boramiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, x, y, par_node={}, depth=0):\n",
    "    \"\"\"\n",
    "    x: Feature set\n",
    "    y: target variable\n",
    "    par_node: will be the tree generated for this x and y. \n",
    "    depth: the depth of the current layer\n",
    "    \"\"\"\n",
    "    if par_node is None:   # base case 1: tree stops at previous level\n",
    "        return None\n",
    "    elif len(y) == 0:   # base case 2: no data in this group\n",
    "        return None\n",
    "    elif self.all_same(y):   # base case 3: all y is the same in this group\n",
    "        return {'val':y[0]}\n",
    "    elif depth >= self.max_depth:   # base case 4: max depth reached \n",
    "        return None\n",
    "    else:   # Recursively generate trees! \n",
    "        # find one split given an information gain \n",
    "        col, cutoff, entropy = self.find_best_split_of_all(x, y)   \n",
    "        y_left = y[x[:, col] < cutoff]  # left hand side data\n",
    "        y_right = y[x[:, col] >= cutoff]  # right hand side data\n",
    "        par_node = {'col': iris.feature_names[col], 'index_col':col,\n",
    "                    'cutoff':cutoff,\n",
    "                   'val': np.round(np.mean(y))}  # save the information \n",
    "        # generate tree for the left hand side data\n",
    "        par_node['left'] = self.fit(x[x[:, col] < cutoff], y_left, {}, depth+1)   \n",
    "        # right hand side trees\n",
    "        par_node['right'] = self.fit(x[x[:, col] >= cutoff], y_right, {}, depth+1)  \n",
    "        self.depth += 1   # increase the depth since we call fit once\n",
    "        self.trees = par_node  \n",
    "        return par_node\n",
    "    \n",
    "def all_same(self, items):\n",
    "    return all(x == items[0] for x in items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaror daraxtini amalga oshirish uchun deyarli barcha funksiyalar tayyor. Endi prognoz qilishni bevosita amalga oshiruvchi funksiyalarga o'tsak bo'ladi. Ushbu funksiyalar, mashq jarayonida tanlanga qoidalar asosida to'plamni bo'laklarga bo'lib prognozni amalga oshiradi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, x):\n",
    "        tree = self.trees\n",
    "        results = np.array([0]*len(x))\n",
    "        for i, c in enumerate(x):\n",
    "            results[i] = self._get_prediction(c)\n",
    "        return results\n",
    "    \n",
    "    def _get_prediction(self, row):\n",
    "        cur_layer = self.trees\n",
    "        while cur_layer.get('cutoff'):\n",
    "            if row[cur_layer['index_col']] < cur_layer['cutoff']:\n",
    "                cur_layer = cur_layer['left']\n",
    "            else:\n",
    "                cur_layer = cur_layer['right']\n",
    "        else:\n",
    "            return cur_layer.get('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yuqorida aniqlangan funksiyalar yordamida, Qaror daraxtining Klassini tuzib chiqamiz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth):\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, x, y, par_node={}, depth=0):\n",
    "        if par_node is None: \n",
    "            return None\n",
    "        elif len(y) == 0:\n",
    "            return None\n",
    "        elif self.all_same(y):\n",
    "            return {'val':y[0]}\n",
    "        elif depth >= self.max_depth: \n",
    "            return None\n",
    "        else: \n",
    "            col, cutoff, entropy = self.find_best_split_of_all(x, y)    # find one split given an information gain \n",
    "            y_left = y[x[:, col] < cutoff]\n",
    "            y_right = y[x[:, col] >= cutoff]\n",
    "            par_node = {'col': iris.feature_names[col], 'index_col':col,\n",
    "                        'cutoff':cutoff,\n",
    "                       'val': np.round(np.mean(y))}\n",
    "            par_node['left'] = self.fit(x[x[:, col] < cutoff], y_left, {}, depth+1)\n",
    "            par_node['right'] = self.fit(x[x[:, col] >= cutoff], y_right, {}, depth+1)\n",
    "            self.depth += 1 \n",
    "            self.trees = par_node\n",
    "            return par_node\n",
    "    \n",
    "    def find_best_split_of_all(self, x, y):\n",
    "        col = None\n",
    "        min_entropy = 1\n",
    "        cutoff = None\n",
    "        for i, c in enumerate(x.T):\n",
    "            entropy, cur_cutoff = self.find_best_split(c, y)\n",
    "            if entropy == 0:    # find the first perfect cutoff. Stop Iterating\n",
    "                return i, cur_cutoff, entropy\n",
    "            elif entropy <= min_entropy:\n",
    "                min_entropy = entropy\n",
    "                col = i\n",
    "                cutoff = cur_cutoff\n",
    "        return col, cutoff, min_entropy\n",
    "    \n",
    "    def find_best_split(self, col, y):\n",
    "        min_entropy = 10\n",
    "        n = len(y)\n",
    "        for value in set(col):\n",
    "            y_predict = col < value\n",
    "            my_entropy = get_entropy(y_predict, y)\n",
    "            if my_entropy <= min_entropy:\n",
    "                min_entropy = my_entropy\n",
    "                cutoff = value\n",
    "        return min_entropy, cutoff\n",
    "    \n",
    "    def all_same(self, items):\n",
    "        return all(x == items[0] for x in items)\n",
    "                                           \n",
    "    def predict(self, x):\n",
    "        tree = self.trees\n",
    "        results = np.array([0]*len(x))\n",
    "        for i, c in enumerate(x):\n",
    "            results[i] = self._get_prediction(c)\n",
    "        return results\n",
    "    \n",
    "    def _get_prediction(self, row):\n",
    "        cur_layer = self.trees\n",
    "        while cur_layer.get('cutoff'):\n",
    "            if row[cur_layer['index_col']] < cur_layer['cutoff']:\n",
    "                cur_layer = cur_layer['left']\n",
    "            else:\n",
    "                cur_layer = cur_layer['right']\n",
    "        else:\n",
    "            return cur_layer.get('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaror daraxti tayyor, endi ushbu qaror daraxtini $iris$ ma'lumotlar to'plamiga tatbiq qilish orqali klassifikatsiya qilamiz. Avvaliga $iris$ to'plamini yuklaylik hamda mashq va nishonlar to'plamini alohida o'zgaruvchilarga $(x, y)$ ajratib olaylik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$sklearn$ bibliotekasining $train\\_test\\_split$ funksiyasidan foydalanib, ma'lumotlar to'plamini mashq hamda test to'plamlariga ajratib olamiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaror daraxtini inisializatsiya qilamiz va mashq jarayonini amalga oshiramiz, bunda mashq jarayoni qaydnomasini $mashq\\_jarayoni$ o'zgaruvchisiga saqlaymiz va chop etamiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col': 'petal width (cm)',\n",
      " 'cutoff': 1.0,\n",
      " 'index_col': 3,\n",
      " 'left': {'val': 0},\n",
      " 'right': {'col': 'petal width (cm)',\n",
      "           'cutoff': 1.6,\n",
      "           'index_col': 3,\n",
      "           'left': {'col': 'petal length (cm)',\n",
      "                    'cutoff': 5.6,\n",
      "                    'index_col': 2,\n",
      "                    'left': {'val': 1},\n",
      "                    'right': {'val': 2},\n",
      "                    'val': 1.0},\n",
      "           'right': {'col': 'petal width (cm)',\n",
      "                     'cutoff': 1.8,\n",
      "                     'index_col': 3,\n",
      "                     'left': {'col': 'petal width (cm)',\n",
      "                              'cutoff': 1.7,\n",
      "                              'index_col': 3,\n",
      "                              'left': {'val': 2},\n",
      "                              'right': {'col': 'sepal length (cm)',\n",
      "                                        'cutoff': 6.7,\n",
      "                                        'index_col': 0,\n",
      "                                        'left': {'val': 2},\n",
      "                                        'right': {'val': 1},\n",
      "                                        'val': 2.0},\n",
      "                              'val': 2.0},\n",
      "                     'right': {'val': 2},\n",
      "                     'val': 2.0},\n",
      "           'val': 2.0},\n",
      " 'val': 1.0}\n"
     ]
    }
   ],
   "source": [
    "qaror_daraxti = DecisionTreeClassifier(max_depth=7)\n",
    "mashq_jarayoni = qaror_daraxti.fit(x_train, y_train)\n",
    "pprint (mashq_jarayoni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaror daraxtining vizual grafida ko'rsatilgan pitonning $dictionary$ qiymati - bizga mashq jarayonida qaror daraxti uchun topilgan qoidalar asosida to'plam qanday bo'linganini ko'rsatib bermoqda. E'tibor bering, bunda \n",
    "\n",
    "- $col$ - qoida sifatida tanlangan ustun, \n",
    "- $cutoff$ - qoida uchun tanlangan qiymat, \n",
    "- $left$ - chap bo'linma to'plam ya'ni,  $[col < cutoff]$ qoidani qanoatlantiradigan bo'linma to'plam (bunda, $value$ - prognoz qilinadigan ustun), \n",
    "- $right$ - o'ng bo'linma to'plam ya'ni, $[col < cutoff]$ qoidani qanoatlantirmaydigan bo'linma to'plam (bunda, to'plamda bir necha klasslar mavjud bo'lsa, bo'linma to'plamni yanada bo'lish amalga oshiriladi).\n",
    "\n",
    "Endi bevosita prognoz qilish jarayoniga o'tsak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "       0, 0, 0, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_test = qaror_daraxti.predict(x_test)\n",
    "predicted_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Endi Qaror daraxtining aniqliligini tekshiramiz. O'tgan bo'limlarda klassifikatsiya muammosi uchun o'lchovlarni ($precision$, $recall$, $f1-score$, $chalkashlik matritsasi$) yozishni o'rgangan edik, va ko'rgan edikki buning uchun bir qancha funksiyalar yozish talab etiladi. Baxtimizga $sklearn$ bibliotekasida deyarli barcha ommabop o'lchovlar uchun paket mavjud. Chalkashlik matritsasi uchun $sklearn$ bibliotekasidan $classification\\_report$ funksiyasini yuklaymiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$classification\\_report$ funksiyasidan foydalangan holda qaror daraxti prognoz qilgan $predicted\\_y\\_test$ massivi hamda haqiqiy nishon qiymatlarini o'zida saqlovchi $y\\_test$ o'rtasidagi chalkashlik matritsasini chop etamiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$F1\\_score$ to'g'risida fikr  Chalkashlik matritsasini chop qilamiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.85      0.73      0.79        15\n",
      "           2       0.75      0.86      0.80        14\n",
      "\n",
      "    accuracy                           0.84        38\n",
      "   macro avg       0.87      0.86      0.86        38\n",
      "weighted avg       0.85      0.84      0.84        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chalkashlik matritsasidan ko'rib turibmizki, 84\\% nishonlar to'g'ri topilgan. $f1\\_score$ o'lchovi qiymatlari quyidagicha tavsiflashimiz mumkin:\n",
    "- $0$ nishonlarning barchasi to'g'ri topilgan\n",
    "- $1$ nishonlarning 73\\% to'g'ri topilgan\n",
    "- $2$ nishonlarning 86\\% to'g'ri topilgan\n",
    "\n",
    "Umuman olib aytganda, qaror daraxtining aniqliligini ancha yaxshi deb baholashimiz mumkin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
